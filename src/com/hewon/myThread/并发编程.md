### 并发编程
### 第一部分
>```markdown
>线程的生命周期
>   1. 阻塞
>   2. 就绪
>   3. 运行
>   4. 中断
>       Java中的线程中断是一种线程间的协作模式，被中断的线程根据中断状态进行自行处理
>       线程睡眠期间其他线程调用该线程的interrupt()方法中断该线程，会在sleep处抛出中断异常
>相关API
>   1. 阻塞
>   2. 就绪
>   3. 运行
>   4. 中断
>       void interrupt()        主动调用线程将目标线程的中断标志位标记为True
>       boolean isInterrupted() 检测当前线程是否被中断，不重置中断标志(ClearInterrupted)
>       boolean interrupted()   检测当前线程是否被中断，重置中断标志(ClearInterrupted)
>```
>```markdown
>上下文切换
>   当前线程使用完时间片后，就会处于就绪状态并让出CPU让其他线程占用，这就是上下文切换，从当前线程的上下文切换到了其他线程。
>   线程上下文切换时机有：当前线程的CPU时间片使用完处于就绪状态时，当前线程被其他线程中断时。
>```

>```markdown
>线程死锁
>   死锁是指两个或两个以上的线程在执行过程中，因争夺资源而造成的互相等待的现象，在无外力作用的情况下，这些线程会一直相互等待而无法继续运行下去
>   1. 互斥条件：指线程对己经获取到的资源进行排它性使用，即该资源同时只由一个线程占用。如果此时还有其他线程请求获取该资源，则请求者只能等待，直至占有资源的线程释放该资源。
>   2. 请求并持有条件：指一个线程己经持有了至少一个资源，但又提出了新的资源请求，而新资源己被其他线程占有，所以当前线程会被阻塞，但阻塞的同时并不释放自 己己经获取的资源。
>   3. 不可剥夺条件：指线程获取到的资源在自己使用完之前不能被其他线程抢占，只有在自己使用完毕后才由自己释放该资源。
>   4. 环路等待条件：指在发生死锁时，必然存在一个线程→资源的环形链。
>破坏线程死锁   
>   1. 避免死锁的核心在于破坏现有条件，实际上只有请求并持有以及环路等待可以被破坏，实际上仔细考虑我们可以发现通过调整资源的请求顺序可以避免死锁情况的出现
>   2. 多线程在获取资源时，对于多线程均需要的资源可以进行排序，所有线程仅在获取了资源n-1时才能获取资源n，比如线程First获取资源1后线程Second无法获取资源1此时陷入阻塞状态
>      线程First继续获取资源2，以此类推知道线程First获取资源n后使用完毕并释放资源n后进行依次释放资源知道释放资源1，此时其他的线程都阻塞在对资源1的获取上，通过线程调度算法选择线程进行资源分配
>```

>```markdown
>守护线程和用户线程
>   1. daemon线程
>       守护线程的结束不影响JVM的退出
>   2. user线程
>       用户线程没有全部结束的情况下，JVM无法退出
>   当一个进程下仅有两个用户线程时，一个线程结束后并不能使得JV退出，当另外一个被改为Daemon后，JVM退出
>   探究JVM底层代码不难发现实际上是通过DestroyJavaVM的线程来等待所有用户线程结束后终止JVM进程
>   Tomcat默认情况下的接收线程以及处理线程都是守护线程
>```

>```markdown
>ThreadLocal
>   对于共享变量的访问多通过同步的方式实现，一般的同步机制是通过加锁的方式实现，但是考虑加锁的话太重量级了，有严重的开销
>   ThreadLocal的机制在于每创建一个变量，每个线程对其进行访问的时候访问的是线程内部的变量，尽管该API构建初期并不是为了解决并发的访问问题
>       如果创建了一个ThreadLocal变量，则需要访问该变量的每个线程都会有一个本地副本
>       多个线程操作变量的时候实际上是操作自己本地的内存变量避免了线程安全问题
>       不同线程之间的本地变量是不能互相访问的，根据该特性我们可以猜测实际上存放每个线程本地变量的不可能是ThreadLocal对象
>   源码追溯
>       通过追溯源码可以看到实际上在调用变量的set方法时，首先获取当前线程，然后调用其threadLocals属性，该属性的本质是一个HashMap
>       然后再在对该map进行值的添加和删除，因此实质上是对每个线程的内部属性进行更改，可以思考一下这里用的设计模式种类？当不需要使用本地变量时可以通过调用ThreadLocal变量的remove方法，从当前线程的threadLocals里面删除该本地变量。
>       至于为什么通过map结构存储，emm，自然是一个线程可能会关联多个变量
>   继承性探讨
>       这里继承的含义在于父线程和子线程之间的关系，即main线程和内部构建的子线程
>       API：InheritableThreadLocal通过将父线程中的inheritableThreadLocals中的信息复制到子线程的该结构中实现继承
>       多用在需要使用父线程信息的场景中，学的不精。。
>```
### 第二部分
>```markdown
> 1.并发编程
>   线程间频繁的上下文切换会带来额外开销，实际场景中线程的个数要多于CPU的个数，因此需要研究的多是并发编程
>   多个CPU意味着每个线程可以使用自己的 CPU 运行，这减少了线程上下文切换的开销，
>   但随着对应用系统性能和吞吐量要求的提高，出现了处理海量数据和请求的要求，这些都对高并发编程有着迫切的需求。
> 2.线程安全问题
>   多个线程同时读写一个共享资源并且没有任何同步措施，导致出现脏数据或者其他不可预见的结果
>   共享资源
>       资源被多个线程所持有或多个线程都可以去访问这个资源
>   典型问题：计算器类的实现存在递增操作-获取计算保存三步操作
>       比如两个线程同时对一个count值进行自增操作，t1时刻线程A从内存读取count到本地，t2时刻线程A进行自增同时线程B读取count到本地
>       t3时刻t1将值写回主内存，之后t4时刻线程B将值协会主内存，即两个加值操作得到的值都是1而不是1和2
>       * 该情况即为共享变量的线程安全问题，因此需要在线程访问共享变量的时候进行同步，一般多使用sychronized关键字同步
> 3.内存可见性问题
>   多线程处理共享变量的内存模型
>       所有的变量都存放在主内存中，线程使用变量时会把主内存里面变量复制到自己的工作空间或工作内存中
>       这个ThreadLocal的概念是不同的，ThreadLocal是基于该值维护自己线程的值，不与其他线程交互
>   实际场景中线程的工作模型
>       比如一个双核CPU场景中，两个CPU中有两个线程同时对主内存中的共享变量进行操作，两个CPU分别有一个控制器和运算器
>       控制器中包含一组寄存器和操作控制器，运算器负责算术逻辑运算，每个CPU还有自己的缓存机制，内存模型的工作内存即这些缓存以及寄存器
>   线程首先将主内存复制到自己的工作内存然后对变量处理后更新到内存中，那么什么是内存可见问题？
>       1. 线程A首先获取共享变量X的值，由于两级Cache都没有命中，所以加载主内存中X的值，假如为0。
>          然后把 X=O 的值缓存到两级缓存，线程A修改X的值为1,然后将其写入两级Cache，并且刷新到主内存。 
>          线程A操作完毕后，线程A所在的CPU的两级Cache内存和主内存里面的X的值都是1.
>       2. 线程B获取X的值，首先一级缓存没有命中，然后看二级缓存，二级缓存命中了，所以返回 X= 1； 
>          到这里一切都是正常的，因为这时候主内存中也是X=1。然后线程B修改X的值为2.
>          并将其存放到线程2所在的一级Cache和共享二级Cache中，最后更新主内存中X的值为2;
>          到这里一切都是好的。
>       3. 线程A这次又需要修改X的值，获取时一级缓存命中，并且X=1，到这里问题就出现了，
>          明明线程B已经把X的值修改为了2，为何线程 A 获取的还是1呢？
>          就是共享变量的内存不可见问题，也就是线程B写入的值对线程A不可见。
>       √  问题解决在于通过java的volatile关键字
> 4.Java中的synchronized关键字
>   0. synchronized块是Java 提供的一种原子性内置锁， Java中的每个对象都可以把它当作一个同步锁来使用，
>      这些 Java 内置的使用者看不到的锁被称为内部锁，也叫作监视器锁。在进入synchronized代码块前会自动获取内部锁，
>      这时候其他线程访问该同步代码块时会被阻塞挂起。拿到内部锁的线程会在正常退出同步代码块或者抛出异常后
>      或者在同步块内调用了该内置锁资源的wait系列方法时释放该内置锁。内置锁是排它锁，
>      也就是当一个线程获取这个锁后，其他线程必须等待该线程释放锁后才能获取该锁。
>   Tips：由于 Java 中的线程是与操作系统的原生线程一一对应的，所以当阻塞一个线程时，
>      需要从用户态切换到内核态执行阻塞操作，这是很耗时的操作，而 synchronized 的使用就会导致上下文切换。
>   1. 内存语义
>      不难看出实际上内存可见性问题在于线程的工作内存。进入 synchronized 块的内存语义是把在 synchronized 
>      块内使用到的变量从线程的工作内存中清除，这样在synchronized块内使用到该变量时就不会从线程的工作内存中获取，
>      而是直接从主内存中获取。退出synchronized块的内存语义是把在synchronized块内对共享变量的修改刷新到主内存。
> 5.Java中的volatile关键字
>   0. Java 还提供了一种弱形式的同步，也就是使用volatile关键字。该关键字可以确保对一个变量的更新对其他线程马上可见。
>      当一个变量被声明为volatile时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存。
>      当其他线程读取该共享变量时，会从主内存重新获取最新值，而不是使用当前线程的工作内存中的值。volatile的内存语义和synchronized有相似之处，
>      具体来说就是，当线程写入了volatile 变量值时就等价于线程退出 synchronized同步块（把写入工作内存的变量值同步到主内存），
>      读取volatile变量值时就相当于进入同步块（先清空本地内存变量值，再从主内存获取最新值）。
>   1. synchronized是独占锁即同一时刻只有一个线程调用get()方法，其他线程会被阻塞，同时会存在线程上下文切换和线程重新调度的开销
>      后者是非阻塞算法，不阻塞就不会造成线程上下文切换的开销，但是虽然提供了内存可见性却不能保证操作的原子性
>   2. 1)写入变量值不依赖变量的当前值时。因为如果依赖当前值，将是获取一计算一写入三步操作，这三步操作不是原子性的，
>        而volatile不保证原子性 。
>      2)读写变量值时没有加锁。因为加锁本身已经保证了内存可见性，这时候不需要把变量声明为volatile的。
> 6.Java中的原子性操作
>   1. 所谓原子性操作，是指执行一系列操作时，这些操作要么全部执行，要么全部不执行，不存在只执行其中一部分的情况 。 
>      在设计计数器时一般都先读取当前值，然后＋1，再更新。这个过程是读改写的过程，
>      如果不能保证这个过程是原子性的，那么就会出现线程安全问题。
>      Tips:这个地方通过汇编代码看底层的执行操作实际上为：
>           简单的＋＋value 由 2 、5 、6 、7 四步组成，其中第2步是获取当前value的值并放入栈顶， 
>           第5步把常量l放入战顶，第6步把当前战顶中两个值相加并把结果放入栈顶，第7步则把栈顶的结果赋给value
>           变量。因此，Java中简单的一句＋＋value被转换为汇编后就不具有原子性了。
>   2. 最直接能保证原子性的操作就是通过synchronized关键字进行同步，通过synchronized关键字可以实现线程安全性
>      即可以保证内存可见性和原子性，但是众所周知synchronized是独占锁，即没有获取内部锁的线程都会被阻塞
>      同时本身get方法不会触发安全性问题，如果添加synchronized更加会降低并发性，而且这个关键字不能去掉，因为要通过synchronized保证可见性
>   3. 基于非阻塞CAS算法实现的原子性操作类AtomicLong实现的方法可以解决原子性问题以及高开销问题
> 7.Java中的CAS操作
>   0. CAS即Compare and Swap，其是JDK提供的非阻塞原子性操作，它通过硬件保证了比较更新操作的原子性。 
>      JDK 里面的 Unsafe类提供了一系列的compareAndSwap＊方法，下面以compareAndSwapLong方法为例进行简单介绍。
>   1. boolean compareAndSwapLong(Object obj,long valueOffset,long expect, long update）方法 ： 
>      其中compareAndSwap的意思是比较并交换。CAS有四个操作数，分别为：
>           对象内存位置、对象中的变量的偏移量、变量预期值和新的值。 
>      其操作含义是：
>           如果对象obj中内存偏移量为 valueOffset的变量值为expect，
>           则使用新的值update替换旧的值expect。这是处理器提供的一个原子性指令。
>   2. 关于CAS操作有个经典的ABA问题 ，具体如下：
>           假如线程I使用CAS修改初始值A的变量X，那么线程I会首先去获取当前变量X的值（为 A 〕
>           然后使用 CAS 操作尝试修改X的值为B，如果使用CAS操作成功了，那么程序运行一定是正确的吗 ？
>           其实未必，这是因为有可能在线程I获取变量X的值A后，在执行CAS前，线程II使用CAS修改了变量X的值为B，
>           然后又使用CAS修改了变量X的值为A。所以虽然线程I执行CAS时X的值是A，但是这个A己经不是线程I获取时的A了。 
>      这就是ABA问题。
>      ABA问题的产生是因为变量的状态值产生了环形转换，就是变量的值可以从A到B,然后再从B到A。
>      如果变量的值只能朝着一个方向转换，比如A到B,B到C，不构成环形，就不会存在问题。
>      JDK中的AtomicStampedReference类给每个变量的状态值都配备了一个时间戳 ，从而避免了 ABA 问题的产生。
> 8.Unsafe类
>   0. 位于JDK中rt.jar包中，提供了硬件级别的原子性操作，其中的方法都是本地方法，通过JNI的方法访问本地C++实现库
>   1. 通过判断类加载器的类型限制类的使用只能在rt.jar包下运行
> 9.一个很有趣的点：Java指令重排序
>   0. Java 内存模型允许编译器和处理器对指令重排序以提高运行性能，并且只会对不存在数据依赖性的指令重排序。 
>      在单线程下重排序可以保证最终执行的结果与程序顺序执行的结果一致，但是在多线程下就会存在问题。
>   1. 所谓的数据依赖性就是当前的指令运算中有使用到其他指令中的数据的情况，比如两个赋值语句和一个加和操作中
>      两个赋值语句的顺序可以随意变化，但是加和操作必须在赋值语句之后
>   2. 写volatile变量时，可以确保volatile写之前的操作不会被编译器重排序到volatile写之后。
>      读volatile变量时，可以确保volatile读之后的操作不会被编译器重排序到volatile读之前。
> 10.伪共享
>   0. 为了解决计算机系统中主内存与CPU之间运行速度差问题，会在CPU与主内存之间添加一级或者多级高速缓冲存储器Cache。
>      这个Cache一般是被集成到CPU内部的，所以也叫CPU Cache，其中一级缓存在每个cpu核内部，二级缓存被多个cpu共享
>      也就是之前我们提到的java内存实际情况
>   1. cache内部按行存储，即cache行是cache与主内存交换数据的基本单位，一般为2的幂次数字节，字节，字节。
>      当CPU访问某个变量时，首先会去看CPU Cache内是否有该变量，如果有则直接从中获取，
>      否则就去主内存里面获取该变量，然后把该变量所在内存区域的一个Cache行大小的内存复制到Cache中。
>      由于存放到 Cache 行的是内存块而不是单个变量，所以可能会把多个变量存放到一个缓存行，
>      当多个线程同时修改一个缓存行里面的多个变量时，由于同时只能有一个线程操作变量，也就是操作缓存行
>      相比每个变量放在一个缓存行性能会下降，即伪共享问题。也就是说多线程需要访问的变量处于同一缓存行时
>      线程A改变其中一个变量后，线程B中的缓存行失效，线程B需要处理的时候要重新从二级缓存/三级缓存进行获取
>      造成了很大的资源浪费以及主内存访问。
>      Tips：缓存一致性协议
>   2. 如上代码声明了四个long变量，假设缓存行的大小为32字节， 那么当CPU访问变量a时，
>      发现该变量没有在缓存中，就会去主内存把变量a以及内存地址附近的b、c、d放入缓存行。
>      也就是地址连续的多个变量才有可能会被放到一个缓存行中。当创建数组时，数组里面的多个元素就会被放入同一个缓存行。
>      那么在单线程下多个变量被放入同一个缓存行对性能有影响吗？其实在正常情况下单线程访问时
>      将数组元素放入一个或者多个缓存行对代码执行是有利的，因为数据都在缓存中，代码执行会更快。
>      而在多线程下并发修改一个缓存行中的多个变量时就会竞争缓存行，从而降低程序运行性能 。
>   3. 伪共享避免机制：
>      1）实际上JDK8之前一般通过字节填充的方式避免，核心在于多线程处理的时候需要保证每个变量单独处于一个缓存行
>         通过在创建变量时使用填充字段填充缓存行。比如：
>           假如缓存行为64字节，那么我们在FilledLong类里面填充了6个long类型的变量，
>           每个long类型变量占用8字节，加上value变量的8字节总共56字节。另外，这里FilledLong是一个类对象， 
>           而类对象的字节码的对象头占用8字节，所以一个 FilledLong对象实际会占用64字节的内存，这正好可以放入一个缓存行。
>       2）JDK8之后提供了sun.misc.Contented注解实现伪共享问题的解决，填充的默认宽度为128字节
> 11.喜闻乐见的环节：锁机制
>   0. 乐观锁和悲观锁（数据库中的概念）
>      悲观锁指对数据被外界修改持保守态度，认为数据很容易就会被其他线程修改，所以在数据被处理前先对数据进行加锁，
>      并在整个数据处理过程中，使数据处于锁定状态。悲观锁的实现往往依靠数据库提供的锁机制，即在数据库中，
>      在对数据记录操作前给记录加排它锁。如果获取锁失败，则说明数据正在被其他线程修改，
>      当前线程则等待或者抛出异常。如果获取锁成功，则对记录进行操作，然后提交事务后释放排它锁。
>
>      乐观锁是相对悲观锁来说的，它认为数据在一般情况下不会造成冲突，所以在访问记录前不会加排它锁，
>      而是在进行数据提交更新时，才会正式对数据冲突与否进行检测。具体来说，根据update返回的行数让用户决定如何去做。
>      Tips：乐观锁并不会使用数据库提供的锁机制，一般在表中添加version字段或者使用业务状态来实现。 
>            乐观锁直到提交时才锁定，所以不会产生任何死锁。
>   2. 公平锁和非公平锁(多线程机制)
>      根据线程获取锁的抢占机制，锁可以分为公平锁和非公平锁，
>      公平锁表示线程获取锁的顺序是按照线程请求锁的时间早晚来决定的，也就是最早请求锁的线程将最早获取到锁 。
>      非公平锁则在运行时闯入，也就是先来不一定先得。
>      API：ReentrantLock 
>           公平锁： ReentrantLock pairLock =new ReentrantLock(true） 
>           非公平锁： ReentrantLock pairLock =new ReentrantLock(false）
>      在没有公平性需求的前提下尽量使用非公平锁，因为公平锁会带来性能开销，为什么？自然是因为你要维护一个队列啊。。。
>   3. 独占锁和共享锁
>      首先我们看到这个分类可以过一下记忆，什么？还有共享锁
>      根据锁只能被单个线程持有还是能被多个线程共同持有，锁可以分为独占锁和共享锁。
>      独占锁保证任何时候都只有一个线程能得到锁， ReentrantLock 就是以独占方式实现的。 
>           独占锁是一种悲观锁，由于每次访问资源都先加上互斥锁，这限制了并发性，
>           因为读操作并不会影响数据的一致性，而独占锁只允许在同一时间由一个线程读取数据，
>           其他线程必须等待当前线程释放锁才能进行读取 。
>      共享锁则可以同时由多个线程持有 ，例如 ReadWriteLock 读写锁，它允许一个资源可以被多线程同时进行读操作 。
>           共享锁则是一种乐观锁，它放宽了加锁的条件，允许多个线程同时进行读操作。
>   4. 可重入锁
>       synchronized内部锁是可重入锁。可重入锁的原理是在锁内部维护一个线程标示，
>       用来标示该锁目前被哪个线程占用，然后关联一个计数器。一开始计数器值为 o,
>       说明该锁没有被任何线程占用 。当一个线程获取了该锁时，计数器的值会变成 1 ，
>       这时其他线程再来获取该锁时会发现锁的所有者不是自己而被阻塞挂起。
>       但是当获取了该锁的线程再次获取锁时发现锁拥有者是自己，就会把计数器值加＋ 1,
>       当释放锁后计数器值－1 。当计数器值为 0 时－，锁里面的线程标示被重置为 null ， 
>       这时候被阻塞的线程会被唤醒来竞争获取该锁 。
>   5. 自旋锁（一个说不上来有没有用的机制，看并发量和场景是否要求高处理吧）
>       由于 Java 中的线程是与操作系统中的线程一一对应的，所以当一个线程在获取锁（比如独占锁）失败后，
>       会被切换到内核状态而被挂起 。 当该线程获取到锁时又需要将其切换到内核状态而唤醒该线程 。 
>       而从用户状态切换到内核状态的开销是比较大的，在一定程度上会影响并发性能。
>       自旋锁则是，当前线程在获取锁时，如果发现锁已经被其他线程占有，它不马上阻塞自己，
>       在不放弃 CPU 使用权的情况下，多次尝试获取（默认次数是 10，可以使用 －XX :PreBlockSpinsh 参数设置该值），
>       很有可能在后面几次尝试中其他线程己经释放了锁 。如果尝试指定的次数后仍没有获取到锁则当前线程才会被阻塞挂起 。 
>       由此看来自旋锁是使用 CPU 时间换取线程阻塞与调度的开销，但是很有可能这些CPU时间白白浪费了。
### 第三部分
>```markdown
>Java并发包中ThreadLocalRandom类原理剖析
>   1. Random类及其局限性
>       JDK7之前包括现在均使用的是java.util.Random实现随机数生成，java.lang.Math中的随机数使用的也是此类
>       实际上在有了Random对象后进行随机数生成操作时，使用的机制实际上是基于现有的随机数种子生成新的随机数种子
>       然后根据现有的随机数种子进行计算随机数，该计算步骤实际上是固定的，因此我们可以想象到：
>           单线程模式下不会产生问题，即每次产生的随机数均不相同
>           多线程模式下会产生相同的随机数，多个线程可能会使用相同的老种子计算新的种子，即得到的新种子是一样的
>               要保证原子性，也就是说当多个线程根据同一个老种子计算新种子时，第一个线程计算新种子后，
>               第二个线程要丢弃自己的老种子，并根据第一个线程的新种子计算自己的新种子
>           Random 函数使用 一个原子变量达到了这个效果，在创建 Random 对象时初始化的种子就被保存到了种子原子变量里面，
>           下面看next（）的代码：
>               protected int next(int bits) {
>                   long oldseed, nextseed;
>                   AtomicLong seed = this.seed;
>                   do {
>                       //获取当前原子变量种子的值
>                       oldseed = seed.get();
>                       //根据当前种子计算新的种子
>                       nextseed = (oldseed * multiplier + addend) & mask;
>                       //基于CAS操作，保证一个线程可以更新老的种子为新的，失败的线程通过循环获取更新后的种子作为当前种子计算新的种子
>                   } while (!seed.compareAndSet(oldseed, nextseed));
>                   //使用固定算法根据新的种子计算随机数
>                   return (int)(nextseed >>> (48 - bits));
>               }
>       每个 Random 实例里面都有一个原子性的种子变量用来记录当前的种子值，当要生成新的随机数时需要根据当前种子计算新的种子并更新回原子变量。
>       在多线程下使用单个Random实例生成随机数时，当多个线程同时计算随机数来计算新的种子时，多个线程会竞争同一个原子变量的更新操作，
>       由于原子变量的更新是CAS操作，同时只有一个线程会成功，所以会造成大量线程进行自旋重试，这会降低并发性能，所以ThreadLocalRandom应运而生。
>   2. ThreadLocalRandom
>       为了弥补多线程高并发情况下Random的缺陷，在 JUC包下新增了ThreadLocalRandom类。
>       调用 ThreadLoca!Random.current（）来获取当前线程的随机数生成器。下面来分析下 ThreadLoca!Random的实现原理 。 
>           从名字上看它会让我们联想到在基础篇中讲解的 ThreadLocal : ThreadLocal 通过让每一个线程复制一份变量，
>           使得在每个线程对变量进行操作时实际是操作自己本地内存里面的副本，从而避免了对共享变量进行同步。
>           实际上ThreadLocalRandom 的实现也是这个原理，Random 的缺点是多个线程会使用同一个原子性种子变量，从而导致对原子变量更新的竞争
>       基于该思想可以大概猜到ThreadLocalRandom的工作机制大概为：每个线程维护一个种子变量，每个线程生成随机数的时候
>           根据自己的老种子进行更新得到新的种子，再根据新种子计算随机数则不会出现Atomic中出现的线程竞争问题，大大提高并发线程
>   3. 源码分析
>       Random
>           -seed:AtomicLong
>           +nextInt(bound:int):int
>       Thread
>           #threadLocalRandomSeed:long
>           #threadLocalRandomProbe:int
>           #threadLocalRandomSecondarySeed:int
>           +currentThread():Thread
>       ThreadLocalRandom
>           -SEED:long
>           -PROBE:long
>           -SECONDARY:long
>           #instance:ThreadLocalRandom
>           -probeGenerator:AtomicInteger
>           -seeder:AtomicLong
>           +nextInt(bound:int):int
>           #nextSeed():long
>           +current():ThreadLocalRandom
>           #localInit():void
>           实际上ThreadLocalRandom中并没有存放具体的种子，具体的种子存放在具体的调用线程的threadLocalRandomSeed变量中
>           可以当作工具人看待，当线程调用ThreadLocalRandom的current法时，
>           ThreadLocalRandom负责初始化调用线程的threadLocalRandomSeed变量，也就是初始化种子
>       当调用ThreadLocalRandom的nextlnt方法时，实际上是获取当前线程的threadLocalRandomSeed变量作为当前种子来计算新的种子，
>           然后更新新的种子到当前线程的threadLocalRandomSeed变量，而后再根据新种子并使用具体算法计算随机数。
>           这里需要注意的是，threadLocalRandomSeed变量就是Thread类里面的一个普通long变量，它并不是原子性变量。
>           其实道理很简单，因为这个变量是线程级别的，所以根本不需要使用原子性变量。
>       其中seeder和probeGenerator是两个原子性变量，在初始化调用线程的种子和探针变量时会用到它们，每个线程只会使用一次。
>       变量instance是ThreadLocalRandom的一个实例，该变量是static的。当多线程通过ThreadLocalRandom的current方法
>           获取ThreadLocalRandom的实例时，其实获取的是同一个实例。但是由于具体的种子是存放在线程里面的，
>           所以在 ThreadLocaIRandom的实例里面只包含与线程无关的通用算法，所以它是线程安全的。
>       1. Unsafe类的机制实在是不想看。。。
>       2. ThreadLocalRandom current()方法
>           需要注意的是，这个方法是静态方法,多个线程返回的是同一个 ThreadLocalRandom 实例。
>           public static ThreadLocalRandom current() {
>               if (UNSAFE.getInt(Thread.currentThread(), PROBE) == 0)
>                   localInit();
>               return instance;
>           }
>           static final void localInit() {
>               int p = probeGenerator.addAndGet(PROBE_INCREMENT);
>               int probe = (p == 0) ? 1 : p; // skip 0
>               long seed = mix64(seeder.getAndAdd(SEEDER_INCREMENT));
>               Thread t = Thread.currentThread();
>               UNSAFE.putLong(t, SEED, seed);
>               UNSAFE.putInt(t, PROBE, probe);
>           }
>       3. int nextInt(int bound)方法
>               public int nextInt(int bound) {
>                   if (bound <= 0)
>                       throw new IllegalArgumentException(BadBound);
>                   int r = mix32(nextSeed());
>                   int m = bound - 1;
>                   if ((bound & m) == 0) // power of two
>                       r &= m;
>                   else { // reject over-represented candidates
>                       for (int u = r >>> 1;
>                            u + m - (r = u % bound) < 0;
>                            u = mix32(nextSeed()) >>> 1)
>                           ;
>                   }
>                   return r;
>               }
>           long nextSeed()方法
>               final long nextSeed() {
>                   Thread t; long r; // read and update per-thread seed
>                   UNSAFE.putLong(t = Thread.currentThread(), SEED,
>                                  r = UNSAFE.getLong(t, SEED) + GAMMA);
>                   return r;
>               }
>           首先使用r = UNSAFE.getLong（t,SEED）获取当前线程中threadLocalRandomSeed变量的值 ，
>              然后在种子的基础上累加GAMMA值作为新种子，而后使用UNSAFE的putLong方法
>              把新种子放入当前线程的threadLocalRandomSeed变量中。
### 第四部分
>```markdown
>Java并发包中原子操作类原理剖析
>   1. 原子变量操作类
>       JUC并发包中含有AtomicInteger、AtomicLong等原子性操作类，原理类似，内部同各国native：Unsafe类来实现
>       通过查看源码我们可以看到AtomicLong类中通过Unsafe.getUnSafe()方法获取Unsafe类的实例，其实观察仔细的话可以发现
>           AtomicLong类也在rt.jar包下，AtomicLong类通过BootStrap类加载器进行加载。
>           AtomicLong类中的value被声明为volatile类型以保证数据的内存可见性
>           数据的原子性基于Unsafe类下的非阻塞CAS锁实现
>           
>    
>```
>
### 第五部分
>```markdown
>1. ArrayList->CopyOnWriteArrayList
>   对其进行修改的操作都是在底层的一个复制的数组上进行的，即写时复制策略。
>   通过追溯源码可以看到：
>           /** The array, accessed only via getArray/setArray. */
>           private transient volatile Object[] array;
>           通过一个Object类型的数组存放具体元素，通过volatile保证内存可见性，通过ReentrantLock独占锁确保原子性即保证只有一个线程访问
>   1. list（array）初始化
>       无参构造器初始化数组
>       有参构造器根据传入的数组对象或者list对象进行复制初始化
>   2. 添加元素
>       调用 add 方法的线程会首先获取独占锁，如果多个线程都调用 add 方法则只有一个线程会获取到该锁，其他线程会被阻塞挂起直到锁被释放。
>       所以一个线程获取到锁后，就保证了在该线程添加元素的过程中其他线程不会对array 进行修改。线程获取锁后通过getArray（）获取 array， 
>       然后复制 array 到一个新数组（从这里可以知道新数组的大小是原来数组大小增加1，CopyOnWriteArrayList 无界list），并把新增的元素添加到新数组。
>       然后使用新数组替换原数组，并在返回前释放锁。由于加了锁，所以整个add过程是个原子性操作。需要注意的是，
>       在添加元素时，首先复制了个快照，然后在快照上进行添加，而不是直接在原来数组上进行。
>   3. 获取指定位置元素
>       当线程x调用get方法获取指定位置的元素时，分两步走，首先获取array数组（这里命名为步骤A），然后通过下标访问指定位置的元素步骤 B ,
>       这是两步操作，但是在整个过程中并没有进行加锁同步。这种机制会导致存在一定的弱一致性问题，即：
>           线程x执行完步骤A后执行步骤B前，另外一个线程y进行了 remove 操作，假设要删除元素1。remove 操作首先会获取独占锁， 
>           然后进行写时复制操作，也就是复制一份当前array数组，然后在复制的数组里面删除线程x通过get方法要访问的元素1，
>           之后让 array指向复制的数组。而这时候array之前指向的数组的引用计数为1而不是0，因为线程 x还在使用它，这时线程x开始执行步骤B，
>           步骤B操作的数组是线程y删除元素之前的数组。即虽然线程y己经删除了index处的元素，但是线程 x 的步骤 B 还是会返回index处的元素。
>   4. 修改指定元素
>       首先获取了独占锁，从而阻止其他线程对array数组进行修改，然后获取当前数组，并调用get方法获取指定位置的元素，
>       如果指定位置的元素值与新值不一致则创建新数组井复制元素，然后在新数组上修改指定位置的元素值并设置新数组到 array。
>       如果指定位置的元素值与新值一样，则为了保证 volatile 语义，还是需要重新设置array，虽然array的内容并没有改变。
>   5. 删除元素
>       首先获取独占锁以保证删除数据期间其他线程不能对 array 进行修改，然后获取数组中要被删除的元素，并把剩余的元素复制到新数组，
>       之后使用新数组替换原来的数组，最后在返回前释放锁 。
>   6. 弱一致性的迭代器
>       众所周知遍历列表元素时可以通过迭代器实现。然而，弱一致性问题出现了。
>       下面来看CopyOnWriteArrayList中迭代器的弱一致性是怎么回事，所谓弱一致性是指返回迭代器后，其他线程对 ist的增删改对迭代器是不可见的。
>           为什么说snapshot是list的快照呢？明明是指针传递的引用啊，而不是副本。如果在该线程使用返回的迭代遍历元素的过程中， 
>           其他线程没有对list进行增删改，那么snapshot本身就是list的array，因为它们是引用关系。但是如果在遍历期间其他线程对该list进行了增删改，
>           那么snapshot就是快照了，因为增删改后list里面的数组被新数组替换了，这时候老数组被snapshot引用这也说明获取迭代器后，
>           使用该迭代器元素时，其他线程对该list进行的增删改不可见，因为它们操作的是两个不同的数组，这就是弱一致性。
>   CopyOnWriteArrayList 使用写时复制的策略来保证 list 的一致性，而获取一修改一写入三步操作并不是原子性的，所以在增删改的过程中都使用了独占锁，
>   来保证在某个时间只有一个线程能对 list 数组进行修改。另外 CopyOnWriteArrayList提供了弱一致性的迭代器，从而保证在获取迭代器后，
>   其他线程对 list 的修改是不可见的，迭代器遍历的数组是一个快照。另外，CopyOnWriteArraySet的底层就是使用它实现的，感兴趣的读者可以查阅相关源码 。
>
>```
### 第六部分：Java并发包中锁原理剖析
>```markdown
>1. 奠基工具人：LockSupport工具类
>   主要作用是挂起和唤醒线程，该工具类是创建锁和其他同步类的基础。LockSupport类与每个使用它的线程都会关联一个许可证，
>       在默认情况下调用LockSupport 类的方法的线程是不持有许可证的。 LockSupport 是使用 Unsafe 类实现的。
>   API：
>   1. void park()方法
>       如果调用 park 方法的线程已经拿到了与 LockSupport 关联的许可证，则调用Locksupport.park()时会马上返回，
>           否则调用线程会被禁止参与线程的调度，也就是会被阻塞挂起。
>       在其他线程调用unpark(Thread thread）方法并且将当前线程作为参数时,调用park方法而被阻塞的线程会返回。
>           另外，如果其他线程调用了阻塞线程的 interrupt()方法设置了中断标志或者线程被虚假唤醒（if和while之争），则阻塞线程也会返回。
>           所以在调用 park 方法时最好也使用循环条件判断方式。需要注意的是，
>               因调用park()方法而被阻塞的线程被其他线程中断而返回时并不会抛出InterruptedException异常。
>   2. void unpark(Thread thread)方法
>       当一个线程调用unpark时，如果参数thread线程没有持有thread与LockSupport 类关联的许可证，则让thread线程持有。 
>           如果thread之前因调用park()而被挂起，则调用unpark后，该线程会被唤醒。如果thread之前没有调用park则调用 unpark 方法后， 
>           再调用park方法，其会立刻返回。park 方法返回时不会告诉你因何种原因返回，所以调用者需要根据之前调用 park方法的原因，
>           再次检查条件是否满足，如果不满足则还需要再次调用 park方法。根据调用前后中断状态的对 比就可以判断是不是因为被中断才返回的 。
>               ／／ 调用 park方 法， 挂起 自己 ， 只有被 中 断 才会退 出 循环
                while (!Thread.currentThread().isinterrupted()) {
                    LockSupport.park()
                }
>   3. 
>```